

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Getting Started: Download MetaShift &mdash; MetaShift 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/all.min.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Preview: Example Images in MetaShift" href="example_images.html" />
    <link rel="prev" title="MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> MetaShift
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting Started: Download MetaShift</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#download-metashift-github-repo">Download MetaShift Github Repo</a></li>
<li class="toctree-l2"><a class="reference internal" href="#downlaod-base-dataset-visual-genome">Downlaod Base Dataset: Visual Genome</a></li>
<li class="toctree-l2"><a class="reference internal" href="#understanding-dataset-meta-data-full-candidate-subsets-pkl">Understanding <code class="docutils literal notranslate"><span class="pre">dataset/meta_data/full-candidate-subsets.pkl</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#generate-the-full-metashift-dataset">Generate the Full MetaShift Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#section-4-2-evaluating-subpopulation-shifts">Section 4.2: Evaluating Subpopulation Shifts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#output-files-mixed-version-for-reproducing-experiments">Output files (mixed version: for reproducing experiments)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#output-files-unmixed-version-for-other-potential-uses">Output files (unmixed version, for other potential uses)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#appendix-d-constructing-metashift-from-coco-dataset">Appendix D: Constructing MetaShift from COCO Dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#install-coco-dependencies">Install COCO Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#coco-data-preparation">COCO Data preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#output-files-mixed-version-for-reproducing-experiments-1">Output files (mixed version: for reproducing experiments)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#section-4-1-evaluating-domain-generalization">Section 4.1: Evaluating Domain Generalization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#output-files-cat-vs-dog-unmixed-version">Output files (cat vs. dog, unmixed version)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#code-for-distribution-shift-experiments">Code for Distribution Shift Experiments</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_images.html">Preview: Example Images in MetaShift</a><ul>
<li class="toctree-l2"><a class="reference internal" href="example_images.html#presence-absence-of-other-objects">Presence/Absence of Other Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_images.html#general-contexts-locations-and-weather">General Contexts (Locations and Weather)</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_images.html#object-attributes">Object Attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_images.html#more-examples-of-meta-graphs">More Examples of Meta-graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="applications.html">Applications of MetaShift</a><ul>
<li class="toctree-l2"><a class="reference internal" href="applications.html#application-evaluating-distribution-shifts">Application: Evaluating Distribution Shifts</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications.html#application-evaluating-subpopulation-shifts">Application: Evaluating Subpopulation Shifts</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications.html#application-accessing-training-conflicts">Application: Accessing Training Conflicts</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MetaShift</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Getting Started: Download MetaShift</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="getting-started-download-metashift">
<h1>Getting Started: Download MetaShift<a class="headerlink" href="#getting-started-download-metashift" title="Permalink to this headline">¶</a></h1>
<div class="section" id="download-metashift-github-repo">
<h2>Download MetaShift Github Repo<a class="headerlink" href="#download-metashift-github-repo" title="Permalink to this headline">¶</a></h2>
<i class="fa fa-github"></i> Download at <a
href="https://github.com/Weixin-Liang/MetaShift"> our GitHub repo.</a>
<br /> <br /></div>
<div class="section" id="downlaod-base-dataset-visual-genome">
<h2>Downlaod Base Dataset: Visual Genome<a class="headerlink" href="#downlaod-base-dataset-visual-genome" title="Permalink to this headline">¶</a></h2>
<p>We leveraged the natural heterogeneity of [Visual Genome](<a class="reference external" href="https://visualgenome.org">https://visualgenome.org</a>) and its annotations to construct MetaShift. Download the pre-processed and cleaned version of Visual Genome by <a class="reference external" href="https://arxiv.org/pdf/1902.09506.pdfL">GQA</a>.</p>
<ul class="simple">
<li><p>Download image files (~20GB) from: <a class="reference external" href="https://nlp.stanford.edu/data/gqa/images.zip">https://nlp.stanford.edu/data/gqa/images.zip</a></p></li>
<li><p>Download the annotations provided the base dataset (scene graphs): <a class="reference external" href="https://nlp.stanford.edu/data/gqa/sceneGraphs.zip">https://nlp.stanford.edu/data/gqa/sceneGraphs.zip</a></p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget -c https://nlp.stanford.edu/data/gqa/images.zip
unzip images.zip -d allImages
wget -c https://nlp.stanford.edu/data/gqa/sceneGraphs.zip
unzip sceneGraphs.zip -d sceneGraphs
</pre></div>
</div>
<ul class="simple">
<li><p>Extract the files. After this step, the base dataset file structure should look like this:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">your_path</span><span class="o">/</span>
    <span class="n">allImages</span><span class="o">/</span>
        <span class="n">images</span><span class="o">/</span>
            <span class="o">&lt;</span><span class="n">ID</span><span class="o">&gt;.</span><span class="n">jpg</span>
            <span class="o">...</span>
    <span class="n">sceneGraphs</span><span class="o">/</span>
        <span class="n">train_sceneGraphs</span><span class="o">.</span><span class="n">json</span>
        <span class="n">val_sceneGraphs</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Specify local path of Visual Genome defined in <code class="docutils literal notranslate"><span class="pre">dataset/Constants.py</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">IMAGE_DATA_FOLDER=/data/GQA/allImages/images/</span></code>).</p></li>
</ul>
</div>
<div class="section" id="understanding-dataset-meta-data-full-candidate-subsets-pkl">
<h2>Understanding <code class="docutils literal notranslate"><span class="pre">dataset/meta_data/full-candidate-subsets.pkl</span></code><a class="headerlink" href="#understanding-dataset-meta-data-full-candidate-subsets-pkl" title="Permalink to this headline">¶</a></h2>
<p>The image IDs for each subset are provided as a Python Dictionary in <code class="docutils literal notranslate"><span class="pre">generate_dataset/meta_data/full-candidate-subsets.pkl</span></code> in the Github repo. The Python scpript <code class="docutils literal notranslate"><span class="pre">generate_dataset/meta_data/create_MetaShift.py</span></code> provides the code for generating the MetaShift.</p>
<p>The metadata file <code class="docutils literal notranslate"><span class="pre">dataset/meta_data/full-candidate-subsets.pkl</span></code> is the most important piece of metadata of MetaShift, which provides the full subset information of MetaShift. To facilitate understanding, we have provided a notebook <code class="docutils literal notranslate"><span class="pre">dataset/understanding_full-candidate-subsets-pkl.ipynb</span></code> to show how to extract information from it.</p>
<p>Basically, the pickle file stores a <code class="docutils literal notranslate"><span class="pre">collections.defaultdict(set)</span></code> object, which contains <em>17,938</em> keys. Each key is a string of the subset name like <code class="docutils literal notranslate"><span class="pre">dog(frisbee)</span></code>, and the corresponding value is a list of the IDs of the images that belong to this subset. The image IDs can be used to retrieve the image files from the Visual Genome dataset that you just downloaded. In our current version, <em>13,543</em> out of <em>17,938</em> subsets have more than 25 valid images. In addition, <code class="docutils literal notranslate"><span class="pre">dataset/meta_data/full-candidate-subsets.pkl</span></code> is drived from the <a class="reference external" href="https://nlp.stanford.edu/data/gqa/sceneGraphs.zip">scene graph annotation</a>, so check it out if your project need additional information about each image.</p>
</div>
<div class="section" id="generate-the-full-metashift-dataset">
<h2>Generate the Full MetaShift Dataset<a class="headerlink" href="#generate-the-full-metashift-dataset" title="Permalink to this headline">¶</a></h2>
<p>Since the total number of all subsets is very large, all of the following scripts only generate a subset of MetaShift. As specified in [dataset/Constants.py](./dataset/Constants.py), we only generate MetaShift for the following classes (subjects). You can add any additional classes (subjects) into the list. See [dataset/meta_data/class_hierarchy.json](./dataset/meta_data/class_hierarchy.json) for the full object vocabulary and its hierarchy.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SELECTED_CLASSES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bus&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">,</span>
    <span class="s1">&#39;elephant&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bowl&#39;</span><span class="p">,</span> <span class="s1">&#39;cup&#39;</span><span class="p">,</span>
    <span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p>In addition, to save storage, all copied images are symbolic links. You can set <code class="docutils literal notranslate"><span class="pre">use_symlink=True</span></code> in the code to perform actual file copying. If you really want to generate the <strong>full</strong> MetaShift, then set <code class="docutils literal notranslate"><span class="pre">ONLY_SELECTED_CLASSES</span> <span class="pre">=</span> <span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">dataset/Constants.py</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> dataset/
python generate_full_MetaShift.py
</pre></div>
</div>
<p>The following files will be generated by executing the script. Modify
the global varaible <code class="docutils literal notranslate"><span class="pre">SUBPOPULATION_SHIFT_DATASET_FOLDER</span></code> to change the
destination folder.</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>/data/MetaShift/MetaDataset-full
├── cat/
    ├── cat(keyboard)/
    ├── cat(sink)/
    ├── ...
├── dog/
    ├── dog(surfboard)
    ├── dog(boat)/
    ├── ...
├── bus/
├── ...
</pre></div>
</div>
<p>Beyond the generated MetaShift dataset, the scipt also genervates the
meta-graphs for each class in <code class="docutils literal notranslate"><span class="pre">dataset/meta-graphs</span></code>.</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>.
├── README.md
├── dataset/
    ├── generate_full_MetaShift.py
    ├── meta-graphs/             (generated meta-graph visualization)
        ├──  cat_graph.jpg
        ├──  dog_graph.jpg
        ├──  ...
    ├── ...
</pre></div>
</div>
</div>
<div class="section" id="section-4-2-evaluating-subpopulation-shifts">
<h2>Section 4.2: Evaluating Subpopulation Shifts<a class="headerlink" href="#section-4-2-evaluating-subpopulation-shifts" title="Permalink to this headline">¶</a></h2>
<p>Run the python script
<code class="docutils literal notranslate"><span class="pre">dataset/subpopulation_shift_cat_dog_indoor_outdoor.py</span></code> to reproduce
the MetaShift subpopulation shift dataset (based on Visual Genome
images) in the paper.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> dataset/
python subpopulation_shift_cat_dog_indoor_outdoor.py
</pre></div>
</div>
<p>The python script generates a “Cat vs. Dog” dataset, where the general
contexts “indoor/outdoor” have a natural spurious correlation with the
class labels.</p>
<p>The following files will be generated by executing the python script
<code class="docutils literal notranslate"><span class="pre">dataset/subpopulation_shift_cat_dog_indoor_outdoor.py</span></code>.</p>
<div class="section" id="output-files-mixed-version-for-reproducing-experiments">
<h3>Output files (mixed version: for reproducing experiments)<a class="headerlink" href="#output-files-mixed-version-for-reproducing-experiments" title="Permalink to this headline">¶</a></h3>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>/data/MetaShift/MetaShift-subpopulation-shift
├── imageID_to_group.pkl
├── train/
    ├── cat/             (more cat(indoor) images than cat(outdoor))
    ├── dog/             (more dog(outdoor) images than cat(indoor))
├── val_out_of_domain/
    ├── cat/             (cat(indoor):cat(outdoor)=1:1)
    ├── dog/             (dog(indoor):dog(outdoor)=1:1)
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">imageID_to_group.pkl</span></code> is a dictionary with 4 keys :
<code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code>. The corresponding value of each key is the list of
the names of the images that belongs to that subset. Modify the global
varaible <code class="docutils literal notranslate"><span class="pre">SUBPOPULATION_SHIFT_DATASET_FOLDER</span></code> to change the
destination folder. You can tune the <code class="docutils literal notranslate"><span class="pre">NUM_MINORITY_IMG</span></code> to control the
amount of subpopulation shift.</p>
</div>
<div class="section" id="output-files-unmixed-version-for-other-potential-uses">
<h3>Output files (unmixed version, for other potential uses)<a class="headerlink" href="#output-files-unmixed-version-for-other-potential-uses" title="Permalink to this headline">¶</a></h3>
<p>To facilitate other potential uses, we also outputs an unmixed version,
where we output the <code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code> into 4 seperate folders. Modify
the global varaible <code class="docutils literal notranslate"><span class="pre">CUSTOM_SPLIT_DATASET_FOLDER</span></code> to change the
destination folder.</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>/data/MetaShift/MetaShift-Cat-Dog-indoor-outdoor
├── imageID_to_group.pkl
├── train/
    ├── cat/             (all cat(indoor) images)
        ├── cat(indoor)/
    ├── dog/             (all dog(outdoor) images)
        ├── dog(outdoor)/
├── test/
    ├── cat/             (all cat(outdoor) images)
        ├── cat(outdoor)/
    ├── dog/             (all dog(indoor) images)
        ├── dog(indoor)/
</pre></div>
</div>
</div>
</div>
<div class="section" id="appendix-d-constructing-metashift-from-coco-dataset">
<h2>Appendix D: Constructing MetaShift from COCO Dataset<a class="headerlink" href="#appendix-d-constructing-metashift-from-coco-dataset" title="Permalink to this headline">¶</a></h2>
<p>The notebook <code class="docutils literal notranslate"><span class="pre">dataset/extend_to_COCO/coco_MetaShift.ipynb</span></code> reproduces
the COCO subpopulation shift dataset in paper Appendix D. Executing the
notebook would construct a “Cat vs. Dog” task based on COCO images,
where the “indoor/outdoor” contexts are spuriously correlated with the
class labels.</p>
<div class="section" id="install-coco-dependencies">
<h3>Install COCO Dependencies<a class="headerlink" href="#install-coco-dependencies" title="Permalink to this headline">¶</a></h3>
<p>Install pycocotools (for evaluation on COCO):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="n">cython</span> <span class="n">scipy</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="s1">&#39;git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="coco-data-preparation">
<h3>COCO Data preparation<a class="headerlink" href="#coco-data-preparation" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://images.cocodataset.org/annotations/annotations_trainval2017.zip">2017 Train/Val annotations
[241MB]</a></p>
<p><a class="reference external" href="http://images.cocodataset.org/zips/train2017.zip">2017 Train images
[118K/18GB]</a></p>
<p>Download and extract COCO 2017 train and val images with annotations
from <a class="reference external" href="http://cocodataset.org/#download">http://cocodataset.org</a>. We
expect the directory structure to be the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">coco</span><span class="o">/</span>
  <span class="n">annotations</span><span class="o">/</span>  <span class="c1"># annotation json files</span>
  <span class="n">train2017</span><span class="o">/</span>    <span class="c1"># train images</span>
  <span class="n">val2017</span><span class="o">/</span>      <span class="c1"># val images</span>
</pre></div>
</div>
<p>Modify the global varaible <code class="docutils literal notranslate"><span class="pre">IMAGE_DATA_FOLDER</span></code> to change the COCO
image folder.</p>
</div>
<div class="section" id="output-files-mixed-version-for-reproducing-experiments-1">
<span id="id1"></span><h3>Output files (mixed version: for reproducing experiments)<a class="headerlink" href="#output-files-mixed-version-for-reproducing-experiments-1" title="Permalink to this headline">¶</a></h3>
<p>The following files will be generated by executing the notebook.</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>/data/MetaShift/COCO-Cat-Dog-indoor-outdoor
├── imageID_to_group.pkl
├── train/
    ├── cat/
    ├── dog/
├── val_out_of_domain/
    ├── cat/
    ├── dog/
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">imageID_to_group.pkl</span></code> is a dictionary with 4 keys :
<code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'cat(outdoor)'</span></code>, <code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'dog(outdoor)'</span></code>. The corresponding value of each key is the list of
the names of the images that belongs to that subset. Modify the global
varaible <code class="docutils literal notranslate"><span class="pre">CUSTOM_SPLIT_DATASET_FOLDER</span></code> to change the destination
folder.</p>
</div>
</div>
<div class="section" id="section-4-1-evaluating-domain-generalization">
<h2>Section 4.1: Evaluating Domain Generalization<a class="headerlink" href="#section-4-1-evaluating-domain-generalization" title="Permalink to this headline">¶</a></h2>
<p>Run the python script <code class="docutils literal notranslate"><span class="pre">dataset/domain_generalization_cat_dog.py</span></code> to
reproduce the MetaShift domain generalization dataset (based on Visual
Genome images) in the paper.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> dataset/
python domain_generalization_cat_dog.py
</pre></div>
</div>
<div class="section" id="output-files-cat-vs-dog-unmixed-version">
<h3>Output files (cat vs. dog, unmixed version)<a class="headerlink" href="#output-files-cat-vs-dog-unmixed-version" title="Permalink to this headline">¶</a></h3>
<p>The following files will be generated by executing the python script
<code class="docutils literal notranslate"><span class="pre">dataset/domain_generalization_cat_dog.py</span></code>. Modify the global varaible
<code class="docutils literal notranslate"><span class="pre">CUSTOM_SPLIT_DATASET_FOLDER</span></code> to change the COCO image folder.</p>
<div class="highlight-plain notranslate"><div class="highlight"><pre><span></span>/data/MetaShift/Domain-Generalization-Cat-Dog
├── train/
    ├── cat/
        ├── cat(sofa)/              (The cat training data is always cat(\emph{sofa + bed}) )
        ├── cat(bed)/               (The cat training data is always cat(\emph{sofa + bed}) )
    ├── dog/
        ├── dog(cabinet)/           (Experiment 1: the dog training data is dog(\emph{cabinet + bed}))
        ├── dog(bed)/               (Experiment 1: the dog training data is dog(\emph{cabinet + bed}))

        ├── dog(bag)/               (Experiment 2: the dog training data is dog(\emph{bag + box}))
        ├── dog(box)/               (Experiment 2: the dog training data is dog(\emph{bag + box}))

        ├── dog(bench)/             (Experiment 3: the dog training data is dog(\emph{bench + bike}))
        ├── dog(bike)/              (Experiment 3: the dog training data is dog(\emph{bench + bike}))

        ├── dog(boat)/              (Experiment 4: the dog training data is dog(\emph{boat + surfboard}))
        ├── dog(surfboard)/         (Experiment 4: the dog training data is dog(\emph{boat + surfboard}))

├── test/
    ├── dog/
        ├── dog(shelf)/             (The test set we used in the paper)
        ├── dog(sofa)/
        ├── dog(grass)/
        ├── dog(vehicle)/
        ├── dog(cap)/
    ├── cat/
        ├── cat(shelf)/
        ├── cat(grass)/
        ├── cat(sink)/
        ├── cat(computer)/
        ├── cat(box)/
        ├── cat(book)/
</pre></div>
</div>
</div>
</div>
<div class="section" id="code-for-distribution-shift-experiments">
<h2>Code for Distribution Shift Experiments<a class="headerlink" href="#code-for-distribution-shift-experiments" title="Permalink to this headline">¶</a></h2>
<p>The python script
<code class="docutils literal notranslate"><span class="pre">experiments/distribution_shift/main_generalization.py</span></code> is the entry
point for running the distribution shift experiemnts for Section 4.2
(Evaluating Subpopulation Shifts) and Appendix D (Constructing MetaShift
from COCO Dataset), and Section 4.1 (Evaluating Domain Generalization).
As a running example, the default value for <code class="docutils literal notranslate"><span class="pre">--data</span></code> in <code class="docutils literal notranslate"><span class="pre">argparse</span></code>
is <code class="docutils literal notranslate"><span class="pre">/data/MetaShift/MetaShift-subpopulation-shift</span></code> (i.e., for Section
4.2).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>clear <span class="o">&amp;&amp;</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">3</span> python main_generalization.py --num-domains <span class="m">2</span> --algorithm ERM
clear <span class="o">&amp;&amp;</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">4</span> python main_generalization.py --num-domains <span class="m">2</span> --algorithm GroupDRO
clear <span class="o">&amp;&amp;</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">5</span> python main_generalization.py --num-domains <span class="m">2</span> --algorithm IRM
clear <span class="o">&amp;&amp;</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">6</span> python main_generalization.py --num-domains <span class="m">2</span> --algorithm CORAL
clear <span class="o">&amp;&amp;</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">7</span> python main_generalization.py --num-domains <span class="m">2</span> --algorithm CDANN
</pre></div>
</div>
<p>Our code is based on the
<a class="reference external" href="https://github.com/facebookresearch/DomainBed">DomainBed</a>, as
introduced in <a class="reference external" href="https://arxiv.org/abs/2007.01434">In Search of Lost Domain
Generalization</a>. The codebase also
provides <a class="reference external" href="experiments/subpopulation_shift/algorithms.py">many additional
algorithms</a>. Many
thanks to the authors and developers!</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="example_images.html" class="btn btn-neutral float-right" title="Preview: Example Images in MetaShift" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../index.html" class="btn btn-neutral float-left" title="MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MetaShift Team.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>